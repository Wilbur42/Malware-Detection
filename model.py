import numpy as np

def train_test_split(data, labels, test_size=0.2, random_seed=None):
    if random_seed is not None:
        np.random.seed(random_seed)

    num_samples = data.shape[0]
    num_test_samples = int(num_samples * test_size)

    # Shuffle the samples
    indices = np.random.permutation(num_samples)

    # Split the samples into training and testing sets
    test_indices = indices[:num_test_samples]
    train_indices = indices[num_test_samples:]

    # Split the data and labels
    train_data = data[train_indices]
    train_labels = labels[train_indices]
    test_data = data[test_indices]
    test_labels = labels[test_indices]

    return train_data, test_data, train_labels, test_labels

def accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)

class DecisionTreeClassifier:
    def __init__(self):
        self.root = None

    # Train the decision tree
    def fit(self, X, y):
        pass

    # Predict the class labels
    def predict(self, X):
        pass

class RandomForestClassifier:
    def __init__(self, n_estimators=100):
        self.n_estimators = n_estimators
        self.decision_trees = []

    # Consturct and Train the decision trees
    def fit(self, X, y):
        for _ in range(self.n_estimators):
            # Create a bootstrap sample
            bootstrap_indices = np.random.choice(X.shape[0], X.shape[0], replace=True)

            # Create a decision tree
            tree = DecisionTreeClassifier()
            tree.fit(X[bootstrap_indices], y[bootstrap_indices])

            # Add the decision tree to the list of decision trees
            self.decision_trees.append(tree)

    # Predict the class labels
    def predict(self, X):
        # Make predictions
        predictions = [tree.predict(X) for tree in self.decision_trees]
