#include <iostream>
#include <fstream>
#include <sstream>
#include <vector>
#include <random>
#include <cmath>
#include <algorithm>
#include <numeric>
#include <unordered_set>
#include <unordered_map>
#include <ctime>

// Decision Tree Node class
class Node {
public:
    Node* left;
    Node* right;
    int featureIndex;
    double threshold;
    int predictedClass;
    bool isLeaf;

    Node() : left(nullptr), right(nullptr), featureIndex(-1), threshold(0.0),
             predictedClass(-1), isLeaf(false) {}
};

// Decision Tree Classifier class
class DecisionTree {
private:
    Node* root;
    int maxDepth;
    int maxFeatures;
    std::vector<std::vector<double>> sortedFeatures;

    // dictionary of fature to featureIndex and threshold
    // std::unordered_map<int, double> bestSplits;

public:
    std::unordered_map<int, double> bestSplits;

    DecisionTree(int maxDepth, int maxfeatures) : root(nullptr), maxDepth(5), maxFeatures(1) {}

    void preprocess(const std::vector<std::vector<double>>& features, const std::vector<int>& labels) {
        calculateBestSplits(features, labels);
        // Output bestSplits
        for (auto& split : bestSplits) {
            std::cout << "Feature: " << split.first << " Threshold: " << split.second << std::endl;
        }
        return;
    }

    // Train decision tree
    void train(const std::vector<std::vector<double>>& features, const std::vector<int>& labels) {
        // Features MUST be sorted for this algorithm to work correctly (accending order)
        root = buildTree(features, labels, 0);
    }

    // Predict class label for a single instance
    int predict(const std::vector<double>& instance) {
        Node* current = root;
        while (current && !current->isLeaf) {
            if (instance[current->featureIndex] <= current->threshold) {
                current = current->left;
            } else {
                current = current->right;
            }
        }
        return current->predictedClass;
    }

private:

    // Build decision tree recursively
    Node* buildTree(const std::vector<std::vector<double>>& features, const std::vector<int>& labels, int depth) {
        Node* node = new Node();
        if (depth >= maxDepth || features.empty() || isPure(labels)) {
            node->isLeaf = true;
            if (!labels.empty()) {
                node->predictedClass = getMajorityClass(labels);
            }
        }
        else {
            std::vector<int> randomFeatureIndex = getRandomFeatures(features[0].size());
            int featureIndex;
            double threshold;
            findBestSplit(features, labels, randomFeatureIndex, featureIndex, threshold);

            node->featureIndex = featureIndex;
            node->threshold = threshold;

            std::vector<std::vector<double>> leftFeatures, rightFeatures;
            std::vector<int> leftLabels, rightLabels;

            splitData(features, labels, featureIndex, threshold, leftFeatures, leftLabels, rightFeatures, rightLabels);

            node->left = buildTree(leftFeatures, leftLabels, depth + 1);
            node->right = buildTree(rightFeatures, rightLabels, depth + 1);
        }
        return node;
    }

    std::vector<int> getRandomFeatures(int num_features) {
        std::vector<int> features(num_features);
        std::iota(features.begin(), features.end(), 0);

        std::random_device rd;
        std::mt19937 g(rd());
        std::shuffle(features.begin(), features.end(), g);

        features.resize(maxFeatures);
        return features;
    }

    // Check if all labels in a set are the same
    bool isPure(const std::vector<int>& labels) {
        if (labels.empty()) {
            return true;
        }
        for (size_t i = 1; i < labels.size(); ++i) {
            if (labels[i] != labels[0]) {
                return false;
            }
        }
        return true;
    }

    // Find the best split point based on Gini impurity
    void findBestSplit(const std::vector<std::vector<double>>& features, const std::vector<int>& labels, const std::vector<int>& randomFeatures,
                       int& bestFeature, double& bestThreshold) {
        double bestGini = std::numeric_limits<double>::max();

        for (size_t featureIndex : randomFeatures) {

            // bestThreshold = bestSplits[featureIndex];
            // bestFeature = featureIndex;
            // break;

            std::vector<double> featureValues;
            for (const auto& instance : features) {
                featureValues.push_back(instance[featureIndex]);
            }

            // As data is pre-sorted, the loop can exit early when the best split is found
            for (size_t i = 0; i < featureValues.size() - 1; ++i) {
                double threshold = (featureValues[i] + featureValues[i + 1]) / 2.0;

                std::vector<std::vector<double>> leftFeatures, rightFeatures;
                std::vector<int> leftLabels, rightLabels;

                splitData(features, labels, featureIndex, threshold, leftFeatures, leftLabels, rightFeatures, rightLabels);

                double gini = calculateGini(leftLabels, rightLabels);
                if (gini < bestGini) {
                    bestGini = gini;
                    bestFeature = featureIndex;
                    bestThreshold = threshold;
                }
                else {
                    // If gini doesn't improve, stop trying for this featureIndex
                    break;
                }
            }
        }
    }

    void calculateBestSplits(const std::vector<std::vector<double>>& features, const std::vector<int>& labels) {
        double bestGini = std::numeric_limits<double>::max();
        double threshold;

        for (size_t featureIndex = 0; featureIndex < features[0].size(); ++featureIndex) {
            std::vector<double> featureValues;
            for (const auto& instance : features) {
                featureValues.push_back(instance[featureIndex]);
            }

            bestSplits[featureIndex] = 0;

            // As data is pre-sorted, the loop can exit early when the best split is found
            for (size_t i = 0; i < featureValues.size() - 1; ++i) {
                double threshold = (featureValues[i] + featureValues[i + 1]) / 2.0;

                std::vector<int> leftLabels, rightLabels;
                std::vector<int> leftCount(2, 0);
                std::vector<int> rightCount(2, 0);
                double giniLeft = 0.0, giniRight = 0.0;

                for (size_t i = 0; i < features.size(); ++i) {
                    if (features[i][featureIndex] <= threshold) {
                        leftLabels.push_back(labels[i]);
                        leftCount[labels[i]]++;
                    } else {
                        rightLabels.push_back(labels[i]);
                        rightCount[labels[i]]++;
                    }
                }

                int numInstances = leftLabels.size() + rightLabels.size();

                if (!leftLabels.empty()) {
                    for (const auto& count : leftCount) {
                        double classProb = static_cast<double>(count) / leftLabels.size();
                        giniLeft += std::pow(classProb, 2);
                    }
                    giniLeft = 1.0 - giniLeft;
                }

                if (!rightLabels.empty()) {
                    for (const auto& count : rightCount) {
                        double classProb = static_cast<double>(count) / rightLabels.size();
                        giniRight += std::pow(classProb, 2);
                    }
                    giniRight = 1.0 - giniRight;
                }

                double gini = (static_cast<double>(leftLabels.size()) / numInstances) * giniLeft
                    + (static_cast<double>(rightLabels.size()) / numInstances) * giniRight;

                if (gini < bestGini) {
                    bestGini = gini;
                    bestSplits[featureIndex] = threshold;
                }
                else {
                    // If gini doesn't improve, stop trying for this featureIndex
                    break;
                }
            }
        }
    }

    // Split the dataset based on the split point
    void splitData(const std::vector<std::vector<double>>& features, const std::vector<int>& labels,
                   int featureIndex, double threshold,
                   std::vector<std::vector<double>>& leftFeatures, std::vector<int>& leftLabels,
                   std::vector<std::vector<double>>& rightFeatures, std::vector<int>& rightLabels) {
        for (size_t i = 0; i < features.size(); ++i) {
            if (features[i][featureIndex] <= threshold) {
                leftFeatures.push_back(features[i]);
                leftLabels.push_back(labels[i]);
            } else {
                rightFeatures.push_back(features[i]);
                rightLabels.push_back(labels[i]);
            }
        }
    }

    // Calculate Gini impurity
    double calculateGini(const std::vector<int>& leftLabels, const std::vector<int>& rightLabels) {
        int numInstances = leftLabels.size() + rightLabels.size();
        double giniLeft = 0.0, giniRight = 0.0;

        if (!leftLabels.empty()) {
            std::vector<int> classCounts(2, 0);
            for (const auto& label : leftLabels) {
                classCounts[label]++;
            }

            for (const auto& count : classCounts) {
                double classProb = static_cast<double>(count) / leftLabels.size();
                giniLeft += std::pow(classProb, 2);
            }
            giniLeft = 1.0 - giniLeft;
        }

        if (!rightLabels.empty()) {
            std::vector<int> classCounts(2, 0);
            for (const auto& label : rightLabels) {
                classCounts[label]++;
            }

            for (const auto& count : classCounts) {
                double classProb = static_cast<double>(count) / rightLabels.size();
                giniRight += std::pow(classProb, 2);
            }
            giniRight = 1.0 - giniRight;
        }

        double gini = (static_cast<double>(leftLabels.size()) / numInstances) * giniLeft
                      + (static_cast<double>(rightLabels.size()) / numInstances) * giniRight;

        return gini;
    }

    int getMajorityClass(const std::vector<int>& labels) {
        std::unordered_map<int, int> classCounts;
        int majorityClass = -1;
        int maxCount = 0;

        for (const auto& label : labels) {
            classCounts[label]++;
            if (classCounts[label] > maxCount) {
                maxCount = classCounts[label];
                majorityClass = label;
            }
        }

        return majorityClass;
    }
};

// Random Forest Classifier class
class RandomForest {
private:
    int numTrees;
    int maxDepth;
    int maxFeatures;
    std::vector<DecisionTree*> trees;

public:
    RandomForest(int numTrees, int maxDepth, int maxFeatures) : numTrees(10), maxDepth(5), maxFeatures(1) {}

    // Train random forest
    void train(const std::vector<std::vector<double>>& features, const std::vector<int>& labels) {
        // DecisionTree* tree = new DecisionTree(maxDepth, maxFeatures);
        // tree->preprocess(features, labels);
        // std::unordered_map<int, double> bestSplits = tree->bestSplits;

        // std::cout << "Preprocessed data" << std::endl;

        // return;

        for (int i = 0; i < numTrees; ++i) {
            clock_t startTime = clock();

            DecisionTree* tree = new DecisionTree(maxDepth, maxFeatures);
            // tree->bestSplits = bestSplits;
            std::vector<std::vector<double>> sampledFeatures;
            std::vector<int> sampledLabels;

            // Sample with replacement
            for (size_t j = 0; j < features.size(); ++j) {
                int index = randomInt(0, features.size() - 1);
                sampledFeatures.push_back(features[index]);
                sampledLabels.push_back(labels[index]);
            }

            // Training features and labels MUST be sorted
            tree->train(sampledFeatures, sampledLabels);
            trees.push_back(tree);

            clock_t endTime = clock();
            double elapsedTime = double(endTime - startTime) / CLOCKS_PER_SEC * 1000.0;

            std::cout << "Trained tree " << i + 1 << ", " << elapsedTime << " ms" << std::endl;
        }
    }

    int predict(const std::vector<double>& instance) {
        std::vector<int> predictions(trees.size());
        for (size_t i = 0; i < trees.size(); ++i) {
            predictions[i] = trees[i]->predict(instance);
        }
        std::vector<int> classCounts(2, 0);
        for (const auto& prediction : predictions) {
            classCounts[prediction]++;
        }
        int maxCount = -1;
        int predictedClass = -1;
        for (size_t i = 0; i < classCounts.size(); ++i) {
            if (classCounts[i] > maxCount) {
                maxCount = classCounts[i];
                predictedClass = i;
            }
        }

        return predictedClass;
    }

    int predict(const std::vector<std::vector<double>>& testFeatures) {
        std::vector<int> predictions(testFeatures.size());
        for (size_t i = 0; i < testFeatures.size(); ++i) {
            predictions[i] = predict(testFeatures[i]);
        }
        // return majority vote
        double one;
        double zero;
        for (const auto& prediction : predictions) {
            if (prediction == 1) {
                one++;
            } else {
                zero++;
            }
        }
        if (one > zero) {
            return 1;
        } else {
            return 0;
        }
    }

    int getNumTrees() {
        return trees.size();
    }

private:

    // Generate a random integer between min and max (inclusive)
    int randomInt(int min, int max) {
        static std::random_device rd;
        static std::mt19937 rng(rd());
        std::uniform_int_distribution<int> uni(min, max);
        return uni(rng);
    }
};

std::vector<std::string> parseHeaderLine(const std::string& line) {
    std::vector<std::string> row;
    std::stringstream ss(line);
    std::string cell;
    while (std::getline(ss, cell, ',')) {
        row.push_back(cell);
    }
    return row;
}

std::vector<double> parseLine(const std::string& line, const std::vector<int>& ignoreIndexes) {
    std::vector<double> row;
    std::stringstream ss(line);
    std::string cell;
    std::unordered_set<int> ignoreSet(ignoreIndexes.begin(), ignoreIndexes.end());

    int cellIndex = 0;
    while (std::getline(ss, cell, ',')) {
        if (ignoreSet.count(cellIndex) == 0 ) {
            row.push_back(std::stod(cell));
        }
        ++cellIndex;
    }

    return row;
}

// Load CSV file into a matrix
bool loadCSV(const std::string& filename, std::vector<std::vector<double>>& data, std::vector<int>& labels) {
    std::ifstream file(filename);
    if (!file.is_open()) {
        std::cout << "Failed to open file: " << filename << std::endl;
        return false;
    }

    std::vector<std::string> ignoreColumns = {"Name", "Parent", "Code", "MD5"};
    std::vector<int> ignoreIndexes;

    std::string flagheader = "Malware";
    int flagIndex;

    // Skip the first line (header)
    std::string line;
    std::getline(file, line);
    std::vector<std::string> header = parseHeaderLine(line);

    int numIgnored = 0;
    for (int i = 0; i < header.size(); i++) {
        for (const auto& ignoreColumn : ignoreColumns) {
            if (header[i] == ignoreColumn) {
                ignoreIndexes.push_back(i);
                numIgnored++;
                break;
            }
            if (header[i] == flagheader) {
                flagIndex = i - numIgnored;
                break;
            }
        }
    }

    while (std::getline(file, line)) {
        std::vector<double> row = parseLine(line, ignoreIndexes);

        if (!row.empty()) {
            labels.push_back(row[flagIndex]);
            row.erase(row.begin() + flagIndex);
            row.pop_back();
            data.push_back(row);
        }
    }

    std::cout << "Loaded " << data.size() << " data points from " << filename << std::endl;

    file.close();
    return true;
}

// Split data into train and test sets
void splitData(const std::vector<std::vector<double>>& allFeatures, const std::vector<int>& allLabels,
               std::vector<std::vector<double>>& trainFeatures, std::vector<int>& trainLabels,
               std::vector<std::vector<double>>& testFeatures, std::vector<int>& testLabels,
               double trainRatio = 0.8) {
    if (allFeatures.size() != allLabels.size()) {
        std::cout << "Mismatch between features and labels!" << std::endl;
        return;
    }

    int numTrainInstances = std::round(allFeatures.size() * trainRatio);

    std::vector<int> indices(allFeatures.size());
    std::iota(indices.begin(), indices.end(), 0);
    std::random_device rd;
    std::mt19937 rng(rd());
    std::shuffle(indices.begin(), indices.end(), rng);

    for (int i = 0; i < numTrainInstances; ++i) {
        trainFeatures.push_back(allFeatures[indices[i]]);
        trainLabels.push_back(allLabels[indices[i]]);
    }

    for (int i = numTrainInstances; i < allFeatures.size(); ++i) {
        testFeatures.push_back(allFeatures[indices[i]]);
        testLabels.push_back(allLabels[indices[i]]);
    }
}

// Calculate accuracy of the model
double calculateAccuracy(const std::vector<std::vector<double>>& testFeatures,
                         const std::vector<int>& testLabels, RandomForest& forest) {
    double correctPredictions = 0;

    for (size_t i = 0; i < testFeatures.size(); ++i) {
        int predictedLabel = forest.predict(testFeatures[i]);
        if (predictedLabel == testLabels[i]) {
            correctPredictions++;
        }
    }

    std::cout << "Correct predictions: " << correctPredictions << "/" << testFeatures.size() << std::endl;

    return correctPredictions / testFeatures.size();
}

// Sort data accending along all dimensions
void sortData(std::vector<std::vector<double>>& features, std::vector<int>& labels) {
    std::vector<std::pair<std::vector<double>, int>> data;
    for (size_t i = 0; i < features.size(); ++i) {
        data.push_back(std::make_pair(features[i], labels[i]));
    }

    std::sort(data.begin(), data.end(), [](const std::pair<std::vector<double>, int>& a,
                                           const std::pair<std::vector<double>, int>& b) {
        return a.first < b.first;
    });

    for (size_t i = 0; i < features.size(); ++i) {
        features[i] = data[i].first;
        labels[i] = data[i].second;
    }
}

int main() {
    std::vector<std::vector<double>> benignFeatures, malwareFeatures, allFeatures, trainFeatures, testFeatures;
    std::vector<int> benignLabels, malwareLabels, allLabels, trainLabels, testLabels;

    // Load data from CSV file
    if (!loadCSV("./inc/benign_data.csv", benignFeatures, benignLabels)) {
        std::cout << "Failed to load CSV file!" << std::endl;
        return 1;
    }

    // Load data from CSV file
    if (!loadCSV("./inc/malware_data.csv", malwareFeatures, malwareLabels)) {
        std::cout << "Failed to load CSV file!" << std::endl;
        return 1;
    }

    int dataPoints = 20000;

    // Merge benign and malware data
    if (dataPoints != -1) {
        allFeatures.insert(allFeatures.end(), benignFeatures.begin(), benignFeatures.begin() + dataPoints);
        allFeatures.insert(allFeatures.end(), malwareFeatures.begin(), malwareFeatures.begin() + dataPoints);
        allLabels.insert(allLabels.end(), benignLabels.begin(), benignLabels.begin() + dataPoints);
        allLabels.insert(allLabels.end(), malwareLabels.begin(), malwareLabels.begin() + dataPoints);
    } else {
        allFeatures.insert(allFeatures.end(), benignFeatures.begin(), benignFeatures.end());
        allFeatures.insert(allFeatures.end(), malwareFeatures.begin(), malwareFeatures.end());
        allLabels.insert(allLabels.end(), benignLabels.begin(), benignLabels.end());
        allLabels.insert(allLabels.end(), malwareLabels.begin(), malwareLabels.end());
    }

    std::cout << "allFeatures size: " << allFeatures.size() << std::endl;

    // Split data into train and test sets
    splitData(allFeatures, allLabels, trainFeatures, trainLabels, testFeatures, testLabels);

    // Training features and labels MUST be sorted
    sortData(trainFeatures, trainLabels);

    clock_t begin = clock();

    // Train the Random Forest
    RandomForest forest(10, 5, 1);
    forest.train(trainFeatures, trainLabels);

    std::cout << "Number of trees: " << forest.getNumTrees() << std::endl;

    clock_t end = clock();
    double elapsed_secs = double(end - begin) / CLOCKS_PER_SEC * 1000.0;
    std::cout << "Training time: " << elapsed_secs << " ms" << std::endl;

    // Evaluate the accuracy of the model
    double accuracy = calculateAccuracy(testFeatures, testLabels, forest);
    std::cout << "Accuracy: " << accuracy << std::endl;

    // Load second test set
    std::vector<std::vector<double>> testFeatures2;
    std::vector<int> testLabels2;

    // Load data from CSV file
    if (!loadCSV("./inc/test_data.csv", testFeatures2, testLabels2)) {
        std::cout << "Failed to load CSV file!" << std::endl;
        return 1;
    }

    // Output features in a row and label in the last column
    for (size_t i = 0; i < testFeatures2.size(); ++i) {
        for (size_t j = 0; j < testFeatures2[i].size(); ++j) {
            std::cout << testFeatures2[i][j] << ",";
        }
        std::cout << std::endl;
        std::cout << "Label: " << testLabels2[i] << std::endl;
    }

    // Sort test features and labels
    sortData(testFeatures2, testLabels2);

    // Evaluate the accuracy of the model
    double predictedLabel = calculateAccuracy(testFeatures2, testLabels2, forest);
    // double predictedLabel = forest.predict(testFeatures2[0]);
    std::cout << "Prediction: " << predictedLabel << std::endl;

    return 0;
}
